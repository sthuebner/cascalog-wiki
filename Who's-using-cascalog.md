<h2> Who's using Cascalog</h2>
<br/>

<table>
<tr>
<td>
<img src="http://www.factual.com/static_images/branding/large_color_logo_horizontal.png" width=400px />
</td>
<td>
<p>Factual is constantly aggregating and processing growing sets of data. We find ourselves relying more and more on the Hadoop stack of technologies. Cascalog has allowed us easy abstraction from details of data sources (with taps, as in cascading). More specifically, we use Cascalog to run our machine learning algorithms on billions of web pages and user contributed data to aggregate factual data present in multiple sources. We also benefit from the ad-hoc nature of Cascalog when doing things such as generating statistics across our datasets, verifying map-reduce job outputs, tracing the history of data through our processing pipeline, and running experimental data manipulation and transformations.</p>
 
<p>We're also benefiting from the availability of Clojure in Cascalog. Clojure is a natural fit when doing custom data manipulations, and it's also quite useful to use the REPL to experiment. Being able to "call out" to pure Clojure from our Cascalog queries has been a big win.</p>
</td>
</tr>

<tr>
<td>
<img src="http://www.premus2007.org/images/supporters/hsph.jpg" width=250px />
</td>
<td>
<p>At Harvard School of Public Health we use Cascalog to query large
datasets generated by next-generation sequencing. We need an approach
that facilitates rapid iterations of coding and testing for
algorithm development work, and then scales to handle increasingly
large data volumes. As a small group that works on many projects
simultaneously, we need to be as efficient as possible since any
development code could potentially become part of processing
pipelines.</p>

<p>Cascalog makes coding for Hadoop much easier. This allows us to
focus on the queries and data interpretation. It additionally
increases the understandability of the code, which is essential for
reproducibility and transparency. A detailed writeup of some of our
work with Cascalog is available <a href="http://bcbio.wordpress.com/2011/07/04/summarizing-next-gen-sequencing-variation-statistics-with-hadoop-using-cascalog/">here</a>.</p>
</td>

</tr>
<tr>
<td>
<img src="http://si0.twimg.com/a/1310175040/images/logos/logo_twitter_withbird_1000_allblue.png" width=250px />
</td>
<td>
<p>Cascalog is at the core of Twitter's tools for publisher partners. A batch workflow written using Clojure and Cascalog updates a variety of !ElephantDB views a few times a day. These views include time series aggregations, influence analysis, follower distribution analysis, and more. Additionally, Cascalog is used to vertically partition the greater than 40TB dataset in a few different ways to allow for efficient querying later on. Cascalog's conciseness and great expressive capabilities greatly reduce the complexity in our batch processing.</p>

<p>Cascalog is also used for ad-hoc querying and exploratory work, taking advantage of the ease of defining and running queries from the REPL. When a major event happens, we extract relevant tweets from the master datastore to a local computer where they can be analyzed in a quick iterative fashion. </p>
</td>
</tr>

</tr>
<tr>
<td>
<img src="http://www.crunchbase.com/assets/images/resized/0000/1336/1336v1-max-250x250.png" width=250px />
</td>
<td>
</td>
</tr>

</tr>
<tr>
<td>
<img src="http://www.crunchbase.com/assets/images/resized/0012/4488/124488v2-max-250x250.png" width=250px />
</td>
<td>
<p>Cascalog forms the core of Yieldbot's intent modeling and matching technology stack. Publisher's data is fed through a batch workflow at regular intervals and performs a wide array of task such as predictive modeling, text processing, metrics aggregation.</p>

<p>Cascalog and Clojure allow us to develop, deploy, explore and iterate on our workflows with extreme speed and minimal effort. You can read about our experience migrating from Apache Pig to Cascalog here: <a href="http://tech.backtype.com/52456836?utm_campaign=cascalog_wiki" target="_blank">Why Yieldbot Chose Cascalog over Pig for Hadoop Processing</a></p>
</td>
</tr>

<tr>
<td>
REDD Metrics
</td>
<td>
<p>REDD Metrics uses Cascalog at the heart of our large-scale deforestation monitoring system, currently housed at the Center for Global Development in Washington. We process hundreds of gigabytes of NASA satellite data down into concrete predictions on the likelihood that some piece of land will be deforested in the next month. Cascalog allows us to generate timeseries and perform analysis at a scale unimaginable with current "state of the art" practices. We look forward to open sourcing our work in the coming months. For updates, take a look at <a href="http://www.reddmetrics.com/blog.html">our blog.</a></p>
</td>
</tr>

</table>